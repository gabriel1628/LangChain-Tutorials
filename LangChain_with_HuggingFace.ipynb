{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriel1628/LangChain-Tutorials/blob/main/LangChain_with_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCTCjEwrcEdf"
      },
      "source": [
        "Source : https://huggingface.co/blog/langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeMhSZGy7I2H",
        "outputId": "1d920083-45b4-49ea-892c-51c5a53349fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U bitsandbytes transformers langchain-huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The LLMs"
      ],
      "metadata": {
        "id": "jjwzA9o15Hsw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HuggingFacePipeline"
      ],
      "metadata": {
        "id": "XSpmU8WdxiCw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB3ATnzTsEjs"
      },
      "outputs": [],
      "source": [
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kGwS_iC5JUs"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "model_id = \"meta-llama/Llama-3.2-1B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    # quantization_config=bnb_config,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    #attn_implementation=\"flash_attention_2\", # if you have an ampere GPU\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oagYE-G2syfx",
        "outputId": "df229c91-24e0-439f-a090-b9cd19c48f35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=100,\n",
        "    top_k=50,\n",
        "    temperature=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3Qnkd836tOk",
        "outputId": "748369e4-7b0a-4eec-dadb-12210dbb9dd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hugging Face is a company that provides a platform for developers to build and deploy machine learning models. The company was founded in 2018 by Alexis Concha and David Robinson. The company has raised $50 million in funding from investors such as Andreessen Horowitz, Index Ventures, and Y Combinator.\n",
            "Hugging Face is a company that provides a platform for developers to build and deploy machine learning models. The company was founded in 2018 by Alexis Concha and David Robinson. The company has raised $\n"
          ]
        }
      ],
      "source": [
        "from langchain_huggingface import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe)\n",
        "text = llm.invoke(\"Hugging Face is\")\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "3oXFEEdyyMpL",
        "outputId": "63b88fbf-c578-4c0d-eef5-c41f81e18ba4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hugging Face is a company that provides a platform for developers to build and deploy machine learning models. The company was founded in 2018 by Alexis Concha and David Robinson. The company has raised $50 million in funding from investors such as Andreessen Horowitz, Index Ventures, and Y Combinator.\\nHugging Face is a company that provides a platform for developers to build and deploy machine learning models. The company was founded in 2018 by Alexis Concha and David Robinson. The company has raised $'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HuggingFaceEndpoint"
      ],
      "metadata": {
        "id": "Q7EERr82zI5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=100,\n",
        "    do_sample=False,\n",
        ")\n",
        "response = llm.invoke(\"Hugging Face is\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq-3LV9Sywn1",
        "outputId": "22e7bfa7-9f9d-4fd4-947e-17adc917820a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " a popular open-source library for natural language processing (NLP) in Python. It provides a wide range of pre-trained models and tools for building NLP applications. Here are some of the key features of Hugging Face:\n",
            "\n",
            "1. Pre-trained Models: Hugging Face provides a wide range of pre-trained models for various NLP tasks such as language translation, sentiment analysis, text classification, and more.\n",
            "2. Transformers: Hugging Face provides a set of pre-trained transformer models, including BERT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatHuggingFace"
      ],
      "metadata": {
        "id": "2JCSxoUz1Rbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
        "from pprint import pprint\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    task=\"text-generation\",\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=False,\n",
        ")\n",
        "llm_engine_hf = ChatHuggingFace(llm=llm)\n",
        "response = llm_engine_hf.invoke(\"Hugging Face is\")\n",
        "\n",
        "pprint(response.response_metadata)\n",
        "print()\n",
        "response.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syMjTT2lzY7d",
        "outputId": "b20c6e54-789e-4983-808a-4d6683ab24d4"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'finish_reason': 'stop',\n",
            " 'model': '',\n",
            " 'token_usage': ChatCompletionOutputUsage(completion_tokens=338,\n",
            "                                          prompt_tokens=14,\n",
            "                                          total_tokens=352)}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "A popular Artificial Intelligence (AI) company!\n",
            "\n",
            "Hugging Face is a privately held AI firm founded in 2018 by Clément Delangue, Thibaut Lamy, and Julien Chaumond. The company is headquartered in New York City, with an office in Paris, France.\n",
            "\n",
            "Hugging Face is known for developing and maintaining a range of AI-related projects and tools, particularly in the areas of natural language processing (NLP) and transformer-based models. Some of their notable projects include:\n",
            "\n",
            "1. **Transformers**: A library for the Hugging Face ecosystem that provides pre-trained models, such as BERT, RoBERTa, and XLNet, for NLP tasks like language translation, sentiment analysis, and question answering.\n",
            "2. **Trainer**: A PyTorch Lightning library that allows developers to easily train and fine-tune transformer models for various NLP tasks.\n",
            "3. **Datasets**: A platform for discovering, uploading, and sharing NLP datasets, making it easier for researchers and developers to access and utilize high-quality data.\n",
            "4. **Hub**: A repository of pre-trained models, datasets, and evaluation scripts, allowing users to easily explore and use a wide range of NLP models and datasets.\n",
            "\n",
            "Hugging Face's mission is to democratize AI and make it more accessible to developers, researchers, and organizations worldwide. They aim to achieve this by providing a comprehensive NLP platform, community-driven resources, and a wide range of pre-trained models and datasets.\n",
            "\n",
            "The company has gained significant attention and recognition in the AI and NLP communities, and has been featured in various media outlets, including The Wall Street Journal, Forbes, and BBC News.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code is equivalent to :\n",
        "```python\n",
        "# with mistralai/Mistral-7B-Instruct-v0.2\n",
        "llm.invoke(\"<s>[INST] Hugging Face is [/INST]\")\n",
        "\n",
        "# with meta-llama/Meta-Llama-3-8B-Instruct\n",
        "llm.invoke(\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>Hugging Face is<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\")\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "knMJMg4A3qWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Embeddings"
      ],
      "metadata": {
        "id": "cLWL6Ixe5P0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "F179liFw5aKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
        "hf_embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        ")\n",
        "\n",
        "texts = [\"Hello, world!\", \"How are you?\"] # lenght 2\n",
        "embeddings = hf_embeddings.embed_documents(texts)\n",
        "len(embeddings), len(embeddings[0]), len(embeddings[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNUL8y-54BNL",
        "outputId": "87402305-6f5e-4718-d958-50a73a083e75"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1024, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HuggingFaceEndpointEmbeddings"
      ],
      "metadata": {
        "id": "pXCcwGuH59wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEndpointEmbeddings\n",
        "\n",
        "hf_embeddings = HuggingFaceEndpointEmbeddings(\n",
        "    model= \"mixedbread-ai/mxbai-embed-large-v1\",\n",
        "    task=\"feature-extraction\",\n",
        "    # huggingfacehub_api_token=\"<HF_TOKEN>\",\n",
        ")\n",
        "\n",
        "texts = [\"Hello, world!\", \"How are you?\"]\n",
        "embeddings = hf_embeddings.embed_documents(texts)\n",
        "len(embeddings), len(embeddings[0]), len(embeddings[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8aBMD6w6PPS",
        "outputId": "d8cd8b4e-65f6-412a-f393-a015f08ca0b2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 1024, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8IgXdJ9f6c-W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgASo2ajzfKMo5LDFqiM7R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}